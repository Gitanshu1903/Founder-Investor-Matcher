{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Import Libraries\n",
    " Import necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Load API Key and Configure Gemini\n",
    "Load the Gemini API key from a `.env` file located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 20:04:59,424 - INFO - Gemini API Key loaded and configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    logging.error(\"CRITICAL: GEMINI_API_KEY not found in .env file. Please create a .env file with your API key.\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        logging.info(\"Gemini API Key loaded and configured.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error configuring Gemini API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Define Constants\n",
    "Define file paths, the Gemini model name, and parameters for controlling API requests (concurrency limit, retry attempts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUNDERS_FILE = \"../data/founders1.csv\"\n",
    "INVESTORS_FILE = \"../data/investors1.csv\"\n",
    "GENERATIVE_MODEL_NAME = \"gemini-1.5-flash-latest\" # or \"gemini-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate Limiting & Retry Configuration\n",
    "MAX_CONCURRENT_REQUESTS = 5\n",
    "RETRY_ATTEMPTS = 3\n",
    "INITIAL_RETRY_DELAY_SECONDS = 5 # (delay after first 429 error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 `load_data` Function\n",
    "This function loads data from the specified CSV file (`founders.csv` or `investors.csv`) into a pandas DataFrame. It performs crucial cleaning steps:\n",
    " *   Specifies the `id_column`'s data type as string during loading.\n",
    " *   Drops rows where the essential `id_column` is missing or empty.\n",
    " *   Fills missing values (`NaN`) in other text columns with empty strings.\n",
    " *   Fills missing values (`NaN`) in numeric columns with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: str, id_column: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a pandas DataFrame.\n",
    "    Ensures the ID column is string and handles missing values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, dtype={id_column: str})\n",
    "        logging.info(f\"Successfully loaded data from {filepath}\")\n",
    "\n",
    "        # Validate ID column presence\n",
    "        if id_column not in df.columns:\n",
    "             logging.error(f\"Error: ID column '{id_column}' not found in {filepath}\")\n",
    "             return None\n",
    "\n",
    "        # Remove rows where the essential ID column is missing or blank.\n",
    "        original_count = len(df)\n",
    "        df.dropna(subset=[id_column], inplace=True)\n",
    "        \n",
    "        df = df[df[id_column].str.strip() != '']\n",
    "        dropped_count = original_count - len(df)\n",
    "        if dropped_count > 0:\n",
    "            logging.warning(f\"Dropped {dropped_count} rows from {filepath} due to missing/empty '{id_column}'.\")\n",
    "\n",
    "        if df.empty:\n",
    "            logging.warning(f\"DataFrame is empty after dropping rows with missing IDs from {filepath}.\")\n",
    "            return df\n",
    "\n",
    "        # Clean other columns\n",
    "        for col in df.columns:\n",
    "            if col == id_column:\n",
    "                continue\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna('').astype(str)\n",
    "            elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        # Final confirmation of ID column \n",
    "        df[id_column] = df[id_column].astype(str)\n",
    "\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading or processing data from {filepath}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Load the Datasets\n",
    "Execute the `load_data` function for both founder and investor CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 20:05:01,274 - INFO - Successfully loaded data from ../data/founders1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 20:05:01,286 - INFO - Successfully loaded data from ../data/investors1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 founders.\n",
      "Loaded 8 investors.\n"
     ]
    }
   ],
   "source": [
    "founders_df = load_data(FOUNDERS_FILE, id_column='startup_id')\n",
    "investors_df = load_data(INVESTORS_FILE, id_column='investor_id')\n",
    "\n",
    "if founders_df is not None:\n",
    "    print(f\"Loaded {len(founders_df)} founders.\")\n",
    "    \n",
    "if investors_df is not None:\n",
    "    print(f\"Loaded {len(investors_df)} investors.\")\n",
    "    \n",
    "if founders_df is None or investors_df is None or founders_df.empty or investors_df.empty:\n",
    "    logging.error(\"Could not load one or both data files, or files are empty after cleaning. Stopping execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Core Matching Logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 `create_match_prompt` Function\n",
    "This function constructs the prompt that will be sent to the Gemini API for each founder-investor pair. A well-structured prompt is key to getting accurate and parseable results.\n",
    " *   **Role Setting:** Instructs the AI on its persona (expert VC analyst).\n",
    " *   **Structured Data:** Presents founder and investor details clearly.\n",
    " *   **Explicit Task:** Defines the criteria for evaluation (industry, stage, funding, geography, qualitative fit).\n",
    " *   **JSON Output Format:** Crucially, demands the response *only* as a JSON object with `score` and `reasoning` fields. This makes automated processing reliable.\n",
    " *   **Scoring Guidance:** Helps the AI calibrate its score according to defined fit levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_match_prompt(founder_data: pd.Series, investor_data: pd.Series) -> str:\n",
    "\n",
    "    # Prepare multi-value fields for readability in the prompt\n",
    "    investor_industries = \", \".join(investor_data.get('preferred_industries', '').split('|'))\n",
    "    investor_stages = \", \".join(investor_data.get('preferred_stages', '').split('|'))\n",
    "    founder_industries = \", \".join(founder_data.get('industry', '').split('|'))\n",
    "    founder_business_models = \", \".join(founder_data.get('business_model', '').split('|'))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the compatibility between the following Startup Founder and Investor. Provide a match score from 0 to 100 and a brief justification.\n",
    "\n",
    "    **Context:** You are an expert Venture Capital analyst specialized in matching startups with the right investors.\n",
    "\n",
    "    **Startup Founder Profile:**\n",
    "    - Name: {founder_data.get('startup_name', 'N/A')}\n",
    "    - Industry: {founder_industries}\n",
    "    - Stage: {founder_data.get('startup_stage', 'N/A')}\n",
    "    - Funding Required (USD): ${founder_data.get('funding_required_usd', 0):,}\n",
    "    - Location: {founder_data.get('location_city', 'N/A')}, {founder_data.get('location_country', 'N/A')}\n",
    "    - Business Model: {founder_business_models}\n",
    "    - MRR (USD): ${founder_data.get('mrr_usd', 0):,}\n",
    "    - User Count: {founder_data.get('user_count', 0)}\n",
    "    - Team Size: {founder_data.get('team_size', 'N/A')}\n",
    "    - Product Description: {founder_data.get('product_description', 'N/A')}\n",
    "    - Unique Selling Proposition (USP): {founder_data.get('usp', 'N/A')}\n",
    "    - Traction Summary: {founder_data.get('traction_summary', 'N/A')}\n",
    "\n",
    "    **Investor Profile:**\n",
    "    - Name: {investor_data.get('investor_name', 'N/A')} ({investor_data.get('investor_type', 'N/A')})\n",
    "    - Preferred Industries: {investor_industries}\n",
    "    - Investment Range (USD): ${investor_data.get('min_investment_usd', 0):,} - ${investor_data.get('max_investment_usd', 0):,}\n",
    "    - Average Check Size (USD): ${investor_data.get('check_size_avg_usd', 0):,}\n",
    "    - Preferred Stages: {investor_stages}\n",
    "    - Geographic Focus: {investor_data.get('geographic_focus', 'N/A')}\n",
    "    - Investment Thesis: {investor_data.get('investment_thesis', 'N/A')}\n",
    "    - Example Portfolio Companies: {investor_data.get('portfolio_companies', 'N/A')}\n",
    "\n",
    "    **Task:**\n",
    "    Evaluate the match based on the following criteria:\n",
    "    1.  **Industry Fit:** Does the startup's industry align with the investor's preferences?\n",
    "    2.  **Stage Fit:** Does the startup's current stage match the investor's preferred investment stages?\n",
    "    3.  **Funding/Check Size Fit:** Is the startup's required funding within the investor's typical investment range or average check size?\n",
    "    4.  **Geographic Focus:** Does the startup's location align with the investor's geographic preferences?\n",
    "    5.  **Qualitative Fit:** Consider the alignment between the startup's product, traction, USP, and business model with the investor's thesis and past investments. Is there a strategic or thesis-driven reason for this investor to be interested?\n",
    "\n",
    "    **Output Format:**\n",
    "    Return your response ONLY as a JSON object with the following structure:\n",
    "    {{\n",
    "      \"score\": <integer between 0 and 100>,\n",
    "      \"reasoning\": \"<string explaining the score based on the criteria>\"\n",
    "    }}\n",
    "\n",
    "    **Scoring Guidance:**\n",
    "    - 85-100: Excellent fit across most key criteria, strong qualitative alignment.\n",
    "    - 70-84: Good fit, alignment on major criteria (e.g., industry, stage), reasonable qualitative fit.\n",
    "    - 50-69: Partial fit, alignment on some criteria but mismatches on others (e.g., stage or check size slightly off, thesis alignment is okay but not perfect).\n",
    "    - 25-49: Weak fit, significant mismatches in core criteria (e.g., wrong industry, wrong stage).\n",
    "    - 0-24: Poor fit, fundamental mismatches across most criteria.\n",
    "\n",
    "    Now, provide the JSON output for the match between {founder_data.get('startup_name', 'this startup')} and {investor_data.get('investor_name', 'this investor')}.\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 `get_match_analysis_async` Function\n",
    "This asynchronous function handles the interaction with the Gemini API for a single founder-investor pair.\n",
    " *   **Concurrency Control:** Uses an `asyncio.Semaphore` to limit the number of simultaneous API requests, preventing rate limit errors.\n",
    " *   **Retry Logic:** Catches `ResourceExhausted` (429) errors and implements exponential backoff retries.\n",
    " *   **Response Parsing:** Attempts to parse the expected JSON response. Handles potential errors during parsing or if the response structure is incorrect.\n",
    " *   **Error Handling:** Includes general exception handling for API call failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_match_analysis_async(\n",
    "    model: genai.GenerativeModel,\n",
    "    prompt: str,\n",
    "    investor_id: str,\n",
    "    semaphore: asyncio.Semaphore\n",
    "    ) -> Tuple[str, Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Calls the Gemini API asynchronously, respecting the semaphore for rate limiting,\n",
    "    and includes retries for 429 errors.\n",
    "    Returns the investor_id and the parsed JSON response or None if an error occurs.\n",
    "    \"\"\"\n",
    "    retries = RETRY_ATTEMPTS\n",
    "    delay = INITIAL_RETRY_DELAY_SECONDS\n",
    "    last_exception = None\n",
    "\n",
    "    async with semaphore: # Acquire semaphore before making API call\n",
    "        for attempt in range(retries + 1):\n",
    "            try:\n",
    "                # Small delay helps slightly spread requests even when semaphore allows multiple\n",
    "                await asyncio.sleep(0.1 * attempt) # Slightly increasing delay within attempts\n",
    "\n",
    "                logging.debug(f\"Attempt {attempt+1}/{retries+1} for investor {investor_id}\")\n",
    "                response = await model.generate_content_async(prompt)\n",
    "\n",
    "                # Check for empty or blocked response\n",
    "                if not response.parts:\n",
    "                     # Check for safety ratings if available and log if blocked\n",
    "                    try:\n",
    "                        if response.prompt_feedback.block_reason:\n",
    "                            logging.warning(f\"Request for investor {investor_id} blocked. Reason: {response.prompt_feedback.block_reason}\")\n",
    "                            return investor_id, None # Blocked, don't retry\n",
    "                    except Exception:\n",
    "                        pass # Ignore if feedback structure isn't as expected\n",
    "                    logging.warning(f\"Received empty response for investor {investor_id} (Attempt {attempt+1}).\")\n",
    "                    # Decide whether to retry empty responses or not; let's not retry for now.\n",
    "                    return investor_id, None\n",
    "\n",
    "                # Extract text and attempt to parse JSON\n",
    "                raw_text = response.text\n",
    "                # Clean potential markdown formatting\n",
    "                if raw_text.strip().startswith(\"```json\"):\n",
    "                    raw_text = raw_text.strip()[7:-3].strip()\n",
    "                elif raw_text.strip().startswith(\"```\"):\n",
    "                     raw_text = raw_text.strip()[3:-3].strip()\n",
    "\n",
    "                try:\n",
    "                    match_data = json.loads(raw_text)\n",
    "                    # Validate structure\n",
    "                    if isinstance(match_data, dict) and \"score\" in match_data and \"reasoning\" in match_data and isinstance(match_data['score'], int):\n",
    "                        logging.info(f\"Successfully received and parsed analysis for investor {investor_id}\")\n",
    "                        return investor_id, match_data\n",
    "                    else:\n",
    "                        logging.warning(f\"Parsed JSON for investor {investor_id} lacks fields or score is not int. Data: {match_data}\")\n",
    "                        return investor_id, None # Malformed JSON structure\n",
    "                except json.JSONDecodeError:\n",
    "                    logging.error(f\"Failed to decode JSON response for investor {investor_id}. Raw text: {raw_text}\")\n",
    "                    return investor_id, None # JSON decode error\n",
    "\n",
    "            except google_exceptions.ResourceExhausted as e:\n",
    "                last_exception = e\n",
    "                if attempt < retries:\n",
    "                    logging.warning(f\"Rate limit hit (429) for investor {investor_id} on attempt {attempt+1}. Retrying in {delay:.2f}s...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                    delay *= 2 # Exponential backoff\n",
    "                else:\n",
    "                    logging.error(f\"Rate limit hit (429) for investor {investor_id}. Max retries ({retries}) exceeded.\")\n",
    "                continue # Go to next attempt in the loop or finish if max retries hit\n",
    "\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logging.error(f\"Error calling Gemini API for investor {investor_id} (Attempt {attempt+1}): {type(e).__name__} - {e}\")\n",
    "                # Break loop on non-429 errors unless specific transient errors are identified for retry\n",
    "                break\n",
    "\n",
    "        # If loop finished without returning a success\n",
    "        logging.error(f\"Failed to get analysis for investor {investor_id} after {retries+1} attempts. Last error: {last_exception or 'Unknown'}\")\n",
    "        return investor_id, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 `find_matches_for_founder` Function\n",
    "This is the main asynchronous function that orchestrates the matching process for a *single* founder.\n",
    " *   Retrieves the specified founder's data.\n",
    " *   Initializes the Gemini model and the `asyncio.Semaphore`.\n",
    " *   Iterates through all valid investors:\n",
    "     *   Validates the `investor_id`.\n",
    "     *   Generates the prompt using `create_match_prompt`.\n",
    "     *   Creates an asynchronous task for `get_match_analysis_async`, passing the semaphore.\n",
    " *   Uses `asyncio.gather` to run all API call tasks concurrently (up to the semaphore limit).\n",
    " *   Processes the results, extracting valid scores and reasons.\n",
    " *   Sorts the matches in descending order by score.\n",
    " *   Returns the sorted list of match dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_matches_for_founder(\n",
    "    founder_id: str,\n",
    "    founders_df: pd.DataFrame,\n",
    "    investors_df: pd.DataFrame\n",
    "    ) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Finds potential investor matches for a specific founder using Gemini API,\n",
    "    with concurrency control and retries.\n",
    "    \"\"\"\n",
    "    if founders_df is None or investors_df is None:\n",
    "        logging.error(\"Input DataFrames are None.\")\n",
    "        return None\n",
    "\n",
    "    founder_row = founders_df[founders_df['startup_id'] == founder_id]\n",
    "    if founder_row.empty:\n",
    "        logging.error(f\"Founder with ID {founder_id} not found in the dataset.\")\n",
    "        return None\n",
    "\n",
    "    founder_data = founder_row.iloc[0]\n",
    "    logging.info(f\"--- Finding matches for Founder: {founder_data.get('startup_name', 'N/A')} ({founder_id}) ---\")\n",
    "\n",
    "    # Check if API key was loaded successfully earlier\n",
    "    if not API_KEY:\n",
    "        logging.error(\"Cannot proceed without Gemini API Key.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Initialize the generative model\n",
    "        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)\n",
    "        # Create a semaphore to limit concurrent requests\n",
    "        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to initialize Gemini Model or Semaphore: {e}\")\n",
    "        return None\n",
    "\n",
    "    tasks = []\n",
    "    investor_map = {} # To map investor_id back to investor details later\n",
    "\n",
    "    # Create async tasks for each valid investor\n",
    "    for index, investor_data in investors_df.iterrows():\n",
    "        investor_id = investor_data.get('investor_id') # Use .get for safety\n",
    "\n",
    "        # --- Check for valid investor_id (redundant if load_data worked, but safe) ---\n",
    "        if not investor_id or str(investor_id).strip() == '':\n",
    "             logging.warning(f\"Skipping row {index} in investors file during task creation due to invalid investor_id: '{investor_id}'\")\n",
    "             continue\n",
    "\n",
    "        investor_id = str(investor_id) # Ensure string key for map\n",
    "\n",
    "        investor_map[investor_id] = investor_data # Store investor data\n",
    "        prompt = create_match_prompt(founder_data, investor_data)\n",
    "        tasks.append(get_match_analysis_async(model, prompt, investor_id, semaphore)) # Pass semaphore\n",
    "\n",
    "    if not tasks:\n",
    "        logging.warning(\"No valid investors found to process for this founder.\")\n",
    "        return []\n",
    "\n",
    "    # Run tasks concurrently, respecting semaphore limit\n",
    "    logging.info(f\"Sending {len(tasks)} requests to Gemini API (max concurrency: {MAX_CONCURRENT_REQUESTS})...\")\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    logging.info(\"Received all responses from Gemini API.\")\n",
    "\n",
    "    # Process results\n",
    "    matches = []\n",
    "    successful_analyses = 0\n",
    "    failed_analyses = 0\n",
    "    for investor_id, analysis_result in results:\n",
    "        # Check if result is valid and score is an integer\n",
    "        if analysis_result and isinstance(analysis_result.get('score'), int):\n",
    "            investor_info = investor_map.get(investor_id)\n",
    "            if investor_info is not None:\n",
    "                matches.append({\n",
    "                    \"investor_id\": investor_id,\n",
    "                    \"investor_name\": investor_info.get('investor_name', 'N/A'),\n",
    "                    \"score\": analysis_result['score'],\n",
    "                    \"reasoning\": analysis_result.get('reasoning', 'N/A')\n",
    "                })\n",
    "                successful_analyses += 1\n",
    "            else:\n",
    "                logging.error(f\"Internal consistency error: Could not find investor info for ID {investor_id} after successful analysis.\")\n",
    "                failed_analyses +=1\n",
    "        else:\n",
    "            # Log failure only if it wasn't just a skipped invalid ID from the start\n",
    "            if investor_id in investor_map:\n",
    "                 logging.warning(f\"No valid analysis received or processed for investor {investor_id}\")\n",
    "                 failed_analyses += 1\n",
    "            # Else: it was likely skipped earlier due to invalid ID, no need to log failure again\n",
    "\n",
    "    logging.info(f\"Analysis summary for founder {founder_id}: {successful_analyses} successful, {failed_analyses} failed/skipped.\")\n",
    "\n",
    "    # Sort matches by score descending\n",
    "    matches.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output Display\n",
    "\n",
    "##### 4.1 `display_matches` Function (Top 5)\n",
    "This function takes the list of matches and displays them in a ranked, readable format. It now includes a `top_n` parameter to limit the output to the top N results (defaulting to 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matches(founder_id: str, matches: List[Dict[str, Any]], top_n: int = 5):\n",
    "    \"\"\"Displays the ranked list of investor matches, showing only the top N.\"\"\"\n",
    "    if matches is None:\n",
    "        print(f\"\\nMatch calculation failed for founder {founder_id}.\")\n",
    "        return\n",
    "    if not matches:\n",
    "        print(f\"\\nNo suitable investor matches found for founder {founder_id}.\")\n",
    "        return\n",
    "\n",
    "    # Get the top N matches, or fewer if less than N matches were found\n",
    "    top_matches = matches[:top_n]\n",
    "    num_to_display = len(top_matches)\n",
    "\n",
    "    # Get founder name for display\n",
    "    founder_name = \"N/A\"\n",
    "    if founders_df is not None:\n",
    "        founder_info = founders_df[founders_df['startup_id'] == founder_id]\n",
    "        if not founder_info.empty:\n",
    "            founder_name = founder_info.iloc[0].get('startup_name', founder_id)\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Top {num_to_display} Investor Matches for {founder_name} ({founder_id}) (Max {top_n}) ---\")\n",
    "    if num_to_display == 0:\n",
    "        print(\"  (No matches met the criteria or processing failed)\")\n",
    "\n",
    "    for i, match in enumerate(top_matches):\n",
    "        print(f\"\\nRank {i+1}:\")\n",
    "        print(f\"  Investor: {match['investor_name']} ({match['investor_id']})\")\n",
    "        print(f\"  Match Score: {match['score']}/100\")\n",
    "        print(f\"  Reasoning: {match['reasoning']}\")\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def display_matches(founder_id: str, matches: List[Dict[str, Any]], top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Displays the ranked list of top N investor matches using a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if matches is None:\n",
    "        # Use HTML for consistent rich output formatting\n",
    "        display(HTML(f\"<p style='color:red;'>Match calculation failed for founder {founder_id}.</p>\"))\n",
    "        return\n",
    "    if not matches:\n",
    "        display(HTML(f\"<p>No suitable investor matches found for founder {founder_id}.</p>\"))\n",
    "        return\n",
    "\n",
    "    # Get the top N matches\n",
    "    top_matches = matches[:top_n]\n",
    "    num_to_display = len(top_matches)\n",
    "\n",
    "    # Get founder name for display (handle potential global scope issue)\n",
    "    founder_name = founder_id # Default to ID if DataFrame not found or error occurs\n",
    "    try:\n",
    "        # Check if founders_df exists in the global scope and is a DataFrame\n",
    "        if 'founders_df' in globals() and isinstance(globals()['founders_df'], pd.DataFrame):\n",
    "            founder_info = globals()['founders_df'][globals()['founders_df']['startup_id'] == founder_id]\n",
    "            if not founder_info.empty:\n",
    "                founder_name = founder_info.iloc[0].get('startup_name', founder_id)\n",
    "        else:\n",
    "            logging.warning(\"founders_df not found or not a DataFrame in global scope. Using Founder ID for display.\")\n",
    "    except Exception as e:\n",
    "         logging.warning(f\"Error accessing founders_df for name lookup: {e}. Using Founder ID.\")\n",
    "\n",
    "\n",
    "    # --- Display Title ---\n",
    "    title_html = f\"<h3>üèÜ Top {num_to_display} Investor Matches for {founder_name} ({founder_id})</h3>\"\n",
    "    display(HTML(title_html))\n",
    "\n",
    "    if num_to_display == 0:\n",
    "        display(HTML(\"<p><i>(No matches met the criteria or processing failed)</i></p>\"))\n",
    "        print(\"-------------------------------------------------------------\") # Keep separator\n",
    "        return\n",
    "\n",
    "    # --- Create DataFrame ---\n",
    "    df_data = []\n",
    "    for i, match in enumerate(top_matches):\n",
    "        df_data.append({\n",
    "            \"Rank\": i + 1,\n",
    "            \"Investor Name\": match.get('investor_name', 'N/A'),\n",
    "            \"Investor ID\": match.get('investor_id', 'N/A'),\n",
    "            \"Score\": match.get('score', 'N/A'),\n",
    "            \"Reasoning\": match.get('reasoning', 'N/A')\n",
    "        })\n",
    "\n",
    "    matches_df = pd.DataFrame(df_data)\n",
    "\n",
    "    # --- Style DataFrame (Optional but recommended) ---\n",
    "    # Center align Score and Rank, left align others\n",
    "    # Add hover effects, customize widths etc.\n",
    "    styles = [\n",
    "        {'selector': 'th', 'props': [('text-align', 'left'), ('font-weight', 'bold')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'left'), ('vertical-align', 'top')]},\n",
    "        {'selector': 'td:nth-child(1), th:nth-child(1)', 'props': [('text-align', 'center'), ('width', '5%')]}, # Rank\n",
    "        {'selector': 'td:nth-child(4), th:nth-child(4)', 'props': [('text-align', 'center'), ('width', '8%')]}, # Score\n",
    "        {'selector': 'td:nth-child(5), th:nth-child(5)', 'props': [('width', '50%')]}, # Reasoning (wider)\n",
    "        {'selector': 'tr:hover', 'props': [('background-color', '#f5f5f5')]} # Hover highlight\n",
    "    ]\n",
    "    styled_df = matches_df.style.set_table_styles(styles).hide(axis=\"index\") # Hide the default pandas index\n",
    "\n",
    "    # Display the styled DataFrame\n",
    "    display(styled_df)\n",
    "    print(\"-------------------------------------------------------------\") # Keep separator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Execution\n",
    "\n",
    "##### 5.1 Final Results\n",
    "This asynchronous function coordinates the overall process: loading data, selecting the founder, running the matching process, and displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 20:05:05,618 - INFO - --- Finding matches for Founder: FinTechFlow (STP001) ---\n",
      "2025-03-28 20:05:05,621 - INFO - Sending 8 requests to Gemini API (max concurrency: 5)...\n",
      "2025-03-28 20:05:09,277 - INFO - Successfully received and parsed analysis for investor INV002\n",
      "2025-03-28 20:05:09,328 - INFO - Successfully received and parsed analysis for investor INV003\n",
      "2025-03-28 20:05:09,506 - INFO - Successfully received and parsed analysis for investor INV005\n",
      "2025-03-28 20:05:09,610 - INFO - Successfully received and parsed analysis for investor INV001\n",
      "2025-03-28 20:05:10,004 - INFO - Successfully received and parsed analysis for investor INV004\n",
      "2025-03-28 20:05:12,128 - INFO - Successfully received and parsed analysis for investor INV006\n",
      "2025-03-28 20:05:12,633 - INFO - Successfully received and parsed analysis for investor INV008\n",
      "2025-03-28 20:05:12,856 - INFO - Successfully received and parsed analysis for investor INV007\n",
      "2025-03-28 20:05:12,857 - INFO - Received all responses from Gemini API.\n",
      "2025-03-28 20:05:12,858 - INFO - Analysis summary for founder STP001: 8 successful, 0 failed/skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>üèÜ Top 5 Investor Matches for FinTechFlow (STP001)</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1daf th {\n",
       "  text-align: left;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_b1daf td {\n",
       "  text-align: left;\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_b1daf td:nth-child(1) {\n",
       "  text-align: center;\n",
       "  width: 5%;\n",
       "}\n",
       "#T_b1daf  th:nth-child(1) {\n",
       "  text-align: center;\n",
       "  width: 5%;\n",
       "}\n",
       "#T_b1daf td:nth-child(4) {\n",
       "  text-align: center;\n",
       "  width: 8%;\n",
       "}\n",
       "#T_b1daf  th:nth-child(4) {\n",
       "  text-align: center;\n",
       "  width: 8%;\n",
       "}\n",
       "#T_b1daf td:nth-child(5) {\n",
       "  width: 50%;\n",
       "}\n",
       "#T_b1daf  th:nth-child(5) {\n",
       "  width: 50%;\n",
       "}\n",
       "#T_b1daf tr:hover {\n",
       "  background-color: #f5f5f5;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1daf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b1daf_level0_col0\" class=\"col_heading level0 col0\" >Rank</th>\n",
       "      <th id=\"T_b1daf_level0_col1\" class=\"col_heading level0 col1\" >Investor Name</th>\n",
       "      <th id=\"T_b1daf_level0_col2\" class=\"col_heading level0 col2\" >Investor ID</th>\n",
       "      <th id=\"T_b1daf_level0_col3\" class=\"col_heading level0 col3\" >Score</th>\n",
       "      <th id=\"T_b1daf_level0_col4\" class=\"col_heading level0 col4\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b1daf_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_b1daf_row0_col1\" class=\"data row0 col1\" >Ben Carter</td>\n",
       "      <td id=\"T_b1daf_row0_col2\" class=\"data row0 col2\" >INV006</td>\n",
       "      <td id=\"T_b1daf_row0_col3\" class=\"data row0 col3\" >85</td>\n",
       "      <td id=\"T_b1daf_row0_col4\" class=\"data row0 col4\" >FinTechFlow and Ben Carter exhibit a strong match across multiple criteria.  \n",
       "\n",
       "1. **Industry Fit:** Excellent.  Both are focused on FinTech and SaaS, a perfect alignment.\n",
       "2. **Stage Fit:** Excellent. FinTechFlow is Seed stage, which aligns perfectly with Ben Carter's preference.\n",
       "3. **Funding/Check Size Fit:** Good. FinTechFlow needs $500,000, which falls within Ben Carter's investment range ($100,000-$500,000) and is close to his average check size of $250,000.  This is a slightly smaller check than his average, but still within his range. \n",
       "4. **Geographic Focus:** Excellent. Both are based in the USA.\n",
       "5. **Qualitative Fit:** Good.  FinTechFlow's AI-powered platform for automated financial reporting for SMEs aligns well with Ben Carter's investment thesis of 'Founder-friendly capital for early-stage SaaS, particularly in FinTech infrastructure.' The 20% MoM growth and 2 pilot customers represent promising early traction.  While specific details about PayAPI and LedgerLite aren't provided, the focus on FinTech infrastructure suggests a potential thematic overlap. The strong team size of 8 is likely viewed as favorable by Ben. The USP of 50% faster reporting is a strong value proposition.  The slight concern is the funding request, which could be considered on the high side for a single angel investor.  However, given the strong alignment on other criteria and the potential for additional funding rounds, this slight mismatch does not heavily impact the overall score. </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b1daf_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_b1daf_row1_col1\" class=\"data row1 col1\" >Alpha Ventures</td>\n",
       "      <td id=\"T_b1daf_row1_col2\" class=\"data row1 col2\" >INV001</td>\n",
       "      <td id=\"T_b1daf_row1_col3\" class=\"data row1 col3\" >75</td>\n",
       "      <td id=\"T_b1daf_row1_col4\" class=\"data row1 col4\" >FinTechFlow and Alpha Ventures exhibit a good fit, though not perfect.  \n",
       "\n",
       "Industry Fit (Excellent): Alpha Ventures' preference for SaaS, AI, and FinTech aligns perfectly with FinTechFlow's industry. \n",
       "\n",
       "Stage Fit (Good): Both are aligned on the Seed stage, a key positive. \n",
       "\n",
       "Funding/Check Size Fit (Fair):  FinTechFlow's $500,000 request falls within Alpha Ventures' investment range. However, it's significantly below their average check size of $2,000,000. This could be a point of concern, as Alpha Ventures might prefer larger investments at this stage. \n",
       "\n",
       "Geographic Focus (Excellent): Both are located in North America (San Francisco). \n",
       "\n",
       "Qualitative Fit (Good): FinTechFlow's focus on AI-powered B2B SaaS solutions in the FinTech space directly aligns with Alpha Ventures' investment thesis. The 20% MoM growth and early traction are positive signals.  However, the limited number of pilot customers (2) and relatively low MRR for a seed-stage company could be a point of concern for an investor who typically invests at a larger scale. The significant difference between FinTechFlow's funding ask and Alpha Venture's average check size might also lead Alpha Ventures to prioritize other investment opportunities that better align with their average investment size.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b1daf_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_b1daf_row2_col1\" class=\"data row2 col1\" >TechNexus Investors</td>\n",
       "      <td id=\"T_b1daf_row2_col2\" class=\"data row2 col2\" >INV004</td>\n",
       "      <td id=\"T_b1daf_row2_col3\" class=\"data row2 col3\" >75</td>\n",
       "      <td id=\"T_b1daf_row2_col4\" class=\"data row2 col4\" >FinTechFlow presents a moderately good fit for TechNexus Investors.  \n",
       "\n",
       "**Industry Fit (Good):** TechNexus's focus on AI aligns well with FinTechFlow's AI-powered platform.  \n",
       "**Stage Fit (Good):** Both are aligned on the Seed stage.\n",
       "**Funding/Check Size Fit (Fair):** FinTechFlow's $500,000 request is significantly lower than TechNexus's average check size of $1,500,000. This could be a challenge, as TechNexus might prefer larger investments at this stage.  While within their investment range, the discrepancy is notable. \n",
       "**Geographic Focus (Excellent):** Both are located in San Francisco, USA, which strongly aligns. \n",
       "**Qualitative Fit (Fair):** FinTechFlow's focus on a B2B SaaS model and its traction (albeit early) show some promise. However,  TechNexus's investment thesis leans toward 'foundational technologies shaping the next iteration of the internet and user interaction.' While FinTechFlow uses AI, its application is more focused on efficiency within a specific niche (SME financial reporting) rather than a broader, foundational technology. The portfolio companies (SynthAI, MetaVerse One, ChainPlay) indicate a preference for potentially more disruptive, consumer-facing, or Web3-related technologies. The strong alignment on AI is the key positive here, offset by the less-disruptive nature of FinTechFlow's product compared to TechNexus's typical investments.  The relatively small funding ask might make it less attractive for a firm that usually invests significantly more at seed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b1daf_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_b1daf_row3_col1\" class=\"data row3 col1\" >Sarah Chen</td>\n",
       "      <td id=\"T_b1daf_row3_col2\" class=\"data row3 col2\" >INV002</td>\n",
       "      <td id=\"T_b1daf_row3_col3\" class=\"data row3 col3\" >35</td>\n",
       "      <td id=\"T_b1daf_row3_col4\" class=\"data row3 col4\" >The fit between FinTechFlow and Sarah Chen is weak. While both align on the Seed stage (Stage Fit), a significant mismatch exists in the industry and funding requirements.  Sarah Chen's focus on HealthTech, EdTech, and Sustainability doesn't align with FinTechFlow's FinTech focus (Industry Fit - low score).  FinTechFlow requires $500,000, which far exceeds Sarah Chen's investment range of $50,000-$250,000 and her average check size of $100,000 (Funding/Check Size Fit - low score).  Geographic focus is aligned (Geographic Focus - high score).  The qualitative fit is also weak; Sarah Chen's impact-focused thesis doesn't strongly resonate with FinTechFlow's product, despite the AI element.  While faster financial reporting is beneficial, it doesn't directly address a major societal challenge in the same way Sarah Chen's portfolio companies do (Qualitative Fit - low score). The overall low scores across key criteria result in a low match score.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b1daf_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_b1daf_row4_col1\" class=\"data row4 col1\" >Innovate Corp Ventures</td>\n",
       "      <td id=\"T_b1daf_row4_col2\" class=\"data row4 col2\" >INV007</td>\n",
       "      <td id=\"T_b1daf_row4_col3\" class=\"data row4 col3\" >35</td>\n",
       "      <td id=\"T_b1daf_row4_col4\" class=\"data row4 col4\" >The match between FinTechFlow and Innovate Corp Ventures is weak. While Innovate Corp Ventures invests in AI, a key component of FinTechFlow's product, several significant mismatches exist.  Firstly, FinTechFlow is at the Seed stage, whereas Innovate Corp Ventures prefers Series A and B. This is a major discrepancy. Secondly, FinTechFlow requires $500,000, far below Innovate Corp Ventures' average check size of $4,000,000 and minimum investment of $1,000,000.  While Innovate Corp Ventures' geographic focus is global and encompasses FinTechFlow's San Francisco location, the qualitative fit is also weak. Innovate Corp Ventures' investment thesis focuses on strategic synergies with its parent company's healthcare and retail operations. FinTechFlow's B2B SaaS platform for SMEs in financial reporting, while using AI, doesn't present an obvious strategic fit with healthcare or retail.  The limited traction of FinTechFlow (3 months old, 2 pilot customers) is also unlikely to appeal to an investor focused on later-stage companies with significant scale.  The industry overlap in AI is the only significant point of alignment, making this a poor fit overall.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c45f0477c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if founders_df is None or investors_df is None or founders_df.empty or investors_df.empty:\n",
    "    logging.error(\"Aborting main execution: Data not loaded correctly.\")\n",
    "    \n",
    "\n",
    "# --- Select Founder to Match ---\n",
    "# Choose a founder ID from your founders.csv file\n",
    "founder_to_match_id = \"STP001\" # Example: FinTechFlow\n",
    "\n",
    "# Validate selected founder ID\n",
    "if founder_to_match_id not in founders_df['startup_id'].values:\n",
    "    logging.error(f\"Founder ID '{founder_to_match_id}' not found in the loaded founders data. Please choose a valid ID.\")\n",
    "    print(f\"\\nValid Founder IDs are: {founders_df['startup_id'].tolist()}\")\n",
    "    \n",
    "\n",
    "# --- Run Matching ---\n",
    "matches = await find_matches_for_founder(founder_to_match_id, founders_df, investors_df)\n",
    "\n",
    "# --- Display Results ---\n",
    "display_matches(founder_to_match_id, matches, top_n=5) # Display top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "This notebook demonstrated how to use the Google Gemini API to build a founder-investor matching system. It loads data, generates prompts, calls the API concurrently with rate limiting and retries, parses the results, and displays the top matches with scores and reasoning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
