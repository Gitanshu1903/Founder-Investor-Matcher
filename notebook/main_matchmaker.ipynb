{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Import Libraries\n",
    " Import necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Load API Key and Configure Gemini\n",
    "Load the Gemini API key from a `.env` file located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 19:50:46,784 - INFO - Gemini API Key loaded and configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    logging.error(\"CRITICAL: GEMINI_API_KEY not found in .env file. Please create a .env file with your API key.\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        logging.info(\"Gemini API Key loaded and configured.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error configuring Gemini API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Define Constants\n",
    "Define file paths, the Gemini model name, and parameters for controlling API requests (concurrency limit, retry attempts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUNDERS_FILE = \"../data/founders1.csv\"\n",
    "INVESTORS_FILE = \"../data/investors1.csv\"\n",
    "GENERATIVE_MODEL_NAME = \"gemini-1.5-flash-latest\" # or \"gemini-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate Limiting & Retry Configuration\n",
    "MAX_CONCURRENT_REQUESTS = 5\n",
    "RETRY_ATTEMPTS = 3\n",
    "INITIAL_RETRY_DELAY_SECONDS = 5 # (delay after first 429 error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 `load_data` Function\n",
    "This function loads data from the specified CSV file (`founders.csv` or `investors.csv`) into a pandas DataFrame. It performs crucial cleaning steps:\n",
    " *   Specifies the `id_column`'s data type as string during loading.\n",
    " *   Drops rows where the essential `id_column` is missing or empty.\n",
    " *   Fills missing values (`NaN`) in other text columns with empty strings.\n",
    " *   Fills missing values (`NaN`) in numeric columns with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: str, id_column: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a pandas DataFrame.\n",
    "    Ensures the ID column is string and handles missing values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, dtype={id_column: str})\n",
    "        logging.info(f\"Successfully loaded data from {filepath}\")\n",
    "\n",
    "        # Validate ID column presence\n",
    "        if id_column not in df.columns:\n",
    "             logging.error(f\"Error: ID column '{id_column}' not found in {filepath}\")\n",
    "             return None\n",
    "\n",
    "        # Remove rows where the essential ID column is missing or blank.\n",
    "        original_count = len(df)\n",
    "        df.dropna(subset=[id_column], inplace=True)\n",
    "        \n",
    "        df = df[df[id_column].str.strip() != '']\n",
    "        dropped_count = original_count - len(df)\n",
    "        if dropped_count > 0:\n",
    "            logging.warning(f\"Dropped {dropped_count} rows from {filepath} due to missing/empty '{id_column}'.\")\n",
    "\n",
    "        if df.empty:\n",
    "            logging.warning(f\"DataFrame is empty after dropping rows with missing IDs from {filepath}.\")\n",
    "            return df\n",
    "\n",
    "        # Clean other columns\n",
    "        for col in df.columns:\n",
    "            if col == id_column:\n",
    "                continue\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna('').astype(str)\n",
    "            elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        # Final confirmation of ID column \n",
    "        df[id_column] = df[id_column].astype(str)\n",
    "\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading or processing data from {filepath}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Load the Datasets\n",
    "Execute the `load_data` function for both founder and investor CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 19:50:51,526 - INFO - Successfully loaded data from ../data/founders1.csv\n",
      "2025-03-28 19:50:51,871 - INFO - Successfully loaded data from ../data/investors1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 founders.\n",
      "Loaded 8 investors.\n"
     ]
    }
   ],
   "source": [
    "founders_df = load_data(FOUNDERS_FILE, id_column='startup_id')\n",
    "investors_df = load_data(INVESTORS_FILE, id_column='investor_id')\n",
    "\n",
    "if founders_df is not None:\n",
    "    print(f\"Loaded {len(founders_df)} founders.\")\n",
    "    \n",
    "if investors_df is not None:\n",
    "    print(f\"Loaded {len(investors_df)} investors.\")\n",
    "    \n",
    "if founders_df is None or investors_df is None or founders_df.empty or investors_df.empty:\n",
    "    logging.error(\"Could not load one or both data files, or files are empty after cleaning. Stopping execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Core Matching Logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 `create_match_prompt` Function\n",
    "This function constructs the prompt that will be sent to the Gemini API for each founder-investor pair. A well-structured prompt is key to getting accurate and parseable results.\n",
    " *   **Role Setting:** Instructs the AI on its persona (expert VC analyst).\n",
    " *   **Structured Data:** Presents founder and investor details clearly.\n",
    " *   **Explicit Task:** Defines the criteria for evaluation (industry, stage, funding, geography, qualitative fit).\n",
    " *   **JSON Output Format:** Crucially, demands the response *only* as a JSON object with `score` and `reasoning` fields. This makes automated processing reliable.\n",
    " *   **Scoring Guidance:** Helps the AI calibrate its score according to defined fit levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_match_prompt(founder_data: pd.Series, investor_data: pd.Series) -> str:\n",
    "\n",
    "    # Prepare multi-value fields for readability in the prompt\n",
    "    investor_industries = \", \".join(investor_data.get('preferred_industries', '').split('|'))\n",
    "    investor_stages = \", \".join(investor_data.get('preferred_stages', '').split('|'))\n",
    "    founder_industries = \", \".join(founder_data.get('industry', '').split('|'))\n",
    "    founder_business_models = \", \".join(founder_data.get('business_model', '').split('|'))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the compatibility between the following Startup Founder and Investor. Provide a match score from 0 to 100 and a brief justification.\n",
    "\n",
    "    **Context:** You are an expert Venture Capital analyst specialized in matching startups with the right investors.\n",
    "\n",
    "    **Startup Founder Profile:**\n",
    "    - Name: {founder_data.get('startup_name', 'N/A')}\n",
    "    - Industry: {founder_industries}\n",
    "    - Stage: {founder_data.get('startup_stage', 'N/A')}\n",
    "    - Funding Required (USD): ${founder_data.get('funding_required_usd', 0):,}\n",
    "    - Location: {founder_data.get('location_city', 'N/A')}, {founder_data.get('location_country', 'N/A')}\n",
    "    - Business Model: {founder_business_models}\n",
    "    - MRR (USD): ${founder_data.get('mrr_usd', 0):,}\n",
    "    - User Count: {founder_data.get('user_count', 0)}\n",
    "    - Team Size: {founder_data.get('team_size', 'N/A')}\n",
    "    - Product Description: {founder_data.get('product_description', 'N/A')}\n",
    "    - Unique Selling Proposition (USP): {founder_data.get('usp', 'N/A')}\n",
    "    - Traction Summary: {founder_data.get('traction_summary', 'N/A')}\n",
    "\n",
    "    **Investor Profile:**\n",
    "    - Name: {investor_data.get('investor_name', 'N/A')} ({investor_data.get('investor_type', 'N/A')})\n",
    "    - Preferred Industries: {investor_industries}\n",
    "    - Investment Range (USD): ${investor_data.get('min_investment_usd', 0):,} - ${investor_data.get('max_investment_usd', 0):,}\n",
    "    - Average Check Size (USD): ${investor_data.get('check_size_avg_usd', 0):,}\n",
    "    - Preferred Stages: {investor_stages}\n",
    "    - Geographic Focus: {investor_data.get('geographic_focus', 'N/A')}\n",
    "    - Investment Thesis: {investor_data.get('investment_thesis', 'N/A')}\n",
    "    - Example Portfolio Companies: {investor_data.get('portfolio_companies', 'N/A')}\n",
    "\n",
    "    **Task:**\n",
    "    Evaluate the match based on the following criteria:\n",
    "    1.  **Industry Fit:** Does the startup's industry align with the investor's preferences?\n",
    "    2.  **Stage Fit:** Does the startup's current stage match the investor's preferred investment stages?\n",
    "    3.  **Funding/Check Size Fit:** Is the startup's required funding within the investor's typical investment range or average check size?\n",
    "    4.  **Geographic Focus:** Does the startup's location align with the investor's geographic preferences?\n",
    "    5.  **Qualitative Fit:** Consider the alignment between the startup's product, traction, USP, and business model with the investor's thesis and past investments. Is there a strategic or thesis-driven reason for this investor to be interested?\n",
    "\n",
    "    **Output Format:**\n",
    "    Return your response ONLY as a JSON object with the following structure:\n",
    "    {{\n",
    "      \"score\": <integer between 0 and 100>,\n",
    "      \"reasoning\": \"<string explaining the score based on the criteria>\"\n",
    "    }}\n",
    "\n",
    "    **Scoring Guidance:**\n",
    "    - 85-100: Excellent fit across most key criteria, strong qualitative alignment.\n",
    "    - 70-84: Good fit, alignment on major criteria (e.g., industry, stage), reasonable qualitative fit.\n",
    "    - 50-69: Partial fit, alignment on some criteria but mismatches on others (e.g., stage or check size slightly off, thesis alignment is okay but not perfect).\n",
    "    - 25-49: Weak fit, significant mismatches in core criteria (e.g., wrong industry, wrong stage).\n",
    "    - 0-24: Poor fit, fundamental mismatches across most criteria.\n",
    "\n",
    "    Now, provide the JSON output for the match between {founder_data.get('startup_name', 'this startup')} and {investor_data.get('investor_name', 'this investor')}.\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 `get_match_analysis_async` Function\n",
    "This asynchronous function handles the interaction with the Gemini API for a single founder-investor pair.\n",
    " *   **Concurrency Control:** Uses an `asyncio.Semaphore` to limit the number of simultaneous API requests, preventing rate limit errors.\n",
    " *   **Retry Logic:** Catches `ResourceExhausted` (429) errors and implements exponential backoff retries.\n",
    " *   **Response Parsing:** Attempts to parse the expected JSON response. Handles potential errors during parsing or if the response structure is incorrect.\n",
    " *   **Error Handling:** Includes general exception handling for API call failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_match_analysis_async(\n",
    "    model: genai.GenerativeModel,\n",
    "    prompt: str,\n",
    "    investor_id: str,\n",
    "    semaphore: asyncio.Semaphore\n",
    "    ) -> Tuple[str, Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Calls the Gemini API asynchronously, respecting the semaphore for rate limiting,\n",
    "    and includes retries for 429 errors.\n",
    "    Returns the investor_id and the parsed JSON response or None if an error occurs.\n",
    "    \"\"\"\n",
    "    retries = RETRY_ATTEMPTS\n",
    "    delay = INITIAL_RETRY_DELAY_SECONDS\n",
    "    last_exception = None\n",
    "\n",
    "    async with semaphore: # Acquire semaphore before making API call\n",
    "        for attempt in range(retries + 1):\n",
    "            try:\n",
    "                # Small delay helps slightly spread requests even when semaphore allows multiple\n",
    "                await asyncio.sleep(0.1 * attempt) # Slightly increasing delay within attempts\n",
    "\n",
    "                logging.debug(f\"Attempt {attempt+1}/{retries+1} for investor {investor_id}\")\n",
    "                response = await model.generate_content_async(prompt)\n",
    "\n",
    "                # Check for empty or blocked response\n",
    "                if not response.parts:\n",
    "                     # Check for safety ratings if available and log if blocked\n",
    "                    try:\n",
    "                        if response.prompt_feedback.block_reason:\n",
    "                            logging.warning(f\"Request for investor {investor_id} blocked. Reason: {response.prompt_feedback.block_reason}\")\n",
    "                            return investor_id, None # Blocked, don't retry\n",
    "                    except Exception:\n",
    "                        pass # Ignore if feedback structure isn't as expected\n",
    "                    logging.warning(f\"Received empty response for investor {investor_id} (Attempt {attempt+1}).\")\n",
    "                    # Decide whether to retry empty responses or not; let's not retry for now.\n",
    "                    return investor_id, None\n",
    "\n",
    "                # Extract text and attempt to parse JSON\n",
    "                raw_text = response.text\n",
    "                # Clean potential markdown formatting\n",
    "                if raw_text.strip().startswith(\"```json\"):\n",
    "                    raw_text = raw_text.strip()[7:-3].strip()\n",
    "                elif raw_text.strip().startswith(\"```\"):\n",
    "                     raw_text = raw_text.strip()[3:-3].strip()\n",
    "\n",
    "                try:\n",
    "                    match_data = json.loads(raw_text)\n",
    "                    # Validate structure\n",
    "                    if isinstance(match_data, dict) and \"score\" in match_data and \"reasoning\" in match_data and isinstance(match_data['score'], int):\n",
    "                        logging.info(f\"Successfully received and parsed analysis for investor {investor_id}\")\n",
    "                        return investor_id, match_data\n",
    "                    else:\n",
    "                        logging.warning(f\"Parsed JSON for investor {investor_id} lacks fields or score is not int. Data: {match_data}\")\n",
    "                        return investor_id, None # Malformed JSON structure\n",
    "                except json.JSONDecodeError:\n",
    "                    logging.error(f\"Failed to decode JSON response for investor {investor_id}. Raw text: {raw_text}\")\n",
    "                    return investor_id, None # JSON decode error\n",
    "\n",
    "            except google_exceptions.ResourceExhausted as e:\n",
    "                last_exception = e\n",
    "                if attempt < retries:\n",
    "                    logging.warning(f\"Rate limit hit (429) for investor {investor_id} on attempt {attempt+1}. Retrying in {delay:.2f}s...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                    delay *= 2 # Exponential backoff\n",
    "                else:\n",
    "                    logging.error(f\"Rate limit hit (429) for investor {investor_id}. Max retries ({retries}) exceeded.\")\n",
    "                continue # Go to next attempt in the loop or finish if max retries hit\n",
    "\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logging.error(f\"Error calling Gemini API for investor {investor_id} (Attempt {attempt+1}): {type(e).__name__} - {e}\")\n",
    "                # Break loop on non-429 errors unless specific transient errors are identified for retry\n",
    "                break\n",
    "\n",
    "        # If loop finished without returning a success\n",
    "        logging.error(f\"Failed to get analysis for investor {investor_id} after {retries+1} attempts. Last error: {last_exception or 'Unknown'}\")\n",
    "        return investor_id, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 `find_matches_for_founder` Function\n",
    "This is the main asynchronous function that orchestrates the matching process for a *single* founder.\n",
    " *   Retrieves the specified founder's data.\n",
    " *   Initializes the Gemini model and the `asyncio.Semaphore`.\n",
    " *   Iterates through all valid investors:\n",
    "     *   Validates the `investor_id`.\n",
    "     *   Generates the prompt using `create_match_prompt`.\n",
    "     *   Creates an asynchronous task for `get_match_analysis_async`, passing the semaphore.\n",
    " *   Uses `asyncio.gather` to run all API call tasks concurrently (up to the semaphore limit).\n",
    " *   Processes the results, extracting valid scores and reasons.\n",
    " *   Sorts the matches in descending order by score.\n",
    " *   Returns the sorted list of match dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_matches_for_founder(\n",
    "    founder_id: str,\n",
    "    founders_df: pd.DataFrame,\n",
    "    investors_df: pd.DataFrame\n",
    "    ) -> Optional[List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Finds potential investor matches for a specific founder using Gemini API,\n",
    "    with concurrency control and retries.\n",
    "    \"\"\"\n",
    "    if founders_df is None or investors_df is None:\n",
    "        logging.error(\"Input DataFrames are None.\")\n",
    "        return None\n",
    "\n",
    "    founder_row = founders_df[founders_df['startup_id'] == founder_id]\n",
    "    if founder_row.empty:\n",
    "        logging.error(f\"Founder with ID {founder_id} not found in the dataset.\")\n",
    "        return None\n",
    "\n",
    "    founder_data = founder_row.iloc[0]\n",
    "    logging.info(f\"--- Finding matches for Founder: {founder_data.get('startup_name', 'N/A')} ({founder_id}) ---\")\n",
    "\n",
    "    # Check if API key was loaded successfully earlier\n",
    "    if not API_KEY:\n",
    "        logging.error(\"Cannot proceed without Gemini API Key.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Initialize the generative model\n",
    "        model = genai.GenerativeModel(GENERATIVE_MODEL_NAME)\n",
    "        # Create a semaphore to limit concurrent requests\n",
    "        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to initialize Gemini Model or Semaphore: {e}\")\n",
    "        return None\n",
    "\n",
    "    tasks = []\n",
    "    investor_map = {} # To map investor_id back to investor details later\n",
    "\n",
    "    # Create async tasks for each valid investor\n",
    "    for index, investor_data in investors_df.iterrows():\n",
    "        investor_id = investor_data.get('investor_id') # Use .get for safety\n",
    "\n",
    "        # --- Check for valid investor_id (redundant if load_data worked, but safe) ---\n",
    "        if not investor_id or str(investor_id).strip() == '':\n",
    "             logging.warning(f\"Skipping row {index} in investors file during task creation due to invalid investor_id: '{investor_id}'\")\n",
    "             continue\n",
    "\n",
    "        investor_id = str(investor_id) # Ensure string key for map\n",
    "\n",
    "        investor_map[investor_id] = investor_data # Store investor data\n",
    "        prompt = create_match_prompt(founder_data, investor_data)\n",
    "        tasks.append(get_match_analysis_async(model, prompt, investor_id, semaphore)) # Pass semaphore\n",
    "\n",
    "    if not tasks:\n",
    "        logging.warning(\"No valid investors found to process for this founder.\")\n",
    "        return []\n",
    "\n",
    "    # Run tasks concurrently, respecting semaphore limit\n",
    "    logging.info(f\"Sending {len(tasks)} requests to Gemini API (max concurrency: {MAX_CONCURRENT_REQUESTS})...\")\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    logging.info(\"Received all responses from Gemini API.\")\n",
    "\n",
    "    # Process results\n",
    "    matches = []\n",
    "    successful_analyses = 0\n",
    "    failed_analyses = 0\n",
    "    for investor_id, analysis_result in results:\n",
    "        # Check if result is valid and score is an integer\n",
    "        if analysis_result and isinstance(analysis_result.get('score'), int):\n",
    "            investor_info = investor_map.get(investor_id)\n",
    "            if investor_info is not None:\n",
    "                matches.append({\n",
    "                    \"investor_id\": investor_id,\n",
    "                    \"investor_name\": investor_info.get('investor_name', 'N/A'),\n",
    "                    \"score\": analysis_result['score'],\n",
    "                    \"reasoning\": analysis_result.get('reasoning', 'N/A')\n",
    "                })\n",
    "                successful_analyses += 1\n",
    "            else:\n",
    "                logging.error(f\"Internal consistency error: Could not find investor info for ID {investor_id} after successful analysis.\")\n",
    "                failed_analyses +=1\n",
    "        else:\n",
    "            # Log failure only if it wasn't just a skipped invalid ID from the start\n",
    "            if investor_id in investor_map:\n",
    "                 logging.warning(f\"No valid analysis received or processed for investor {investor_id}\")\n",
    "                 failed_analyses += 1\n",
    "            # Else: it was likely skipped earlier due to invalid ID, no need to log failure again\n",
    "\n",
    "    logging.info(f\"Analysis summary for founder {founder_id}: {successful_analyses} successful, {failed_analyses} failed/skipped.\")\n",
    "\n",
    "    # Sort matches by score descending\n",
    "    matches.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output Display\n",
    "\n",
    "##### 4.1 `display_matches` Function (Top 5)\n",
    "This function takes the list of matches and displays them in a ranked, readable format. It now includes a `top_n` parameter to limit the output to the top N results (defaulting to 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matches(founder_id: str, matches: List[Dict[str, Any]], top_n: int = 5):\n",
    "    \"\"\"Displays the ranked list of investor matches, showing only the top N.\"\"\"\n",
    "    if matches is None:\n",
    "        print(f\"\\nMatch calculation failed for founder {founder_id}.\")\n",
    "        return\n",
    "    if not matches:\n",
    "        print(f\"\\nNo suitable investor matches found for founder {founder_id}.\")\n",
    "        return\n",
    "\n",
    "    # Get the top N matches, or fewer if less than N matches were found\n",
    "    top_matches = matches[:top_n]\n",
    "    num_to_display = len(top_matches)\n",
    "\n",
    "    # Get founder name for display\n",
    "    founder_name = \"N/A\"\n",
    "    if founders_df is not None:\n",
    "        founder_info = founders_df[founders_df['startup_id'] == founder_id]\n",
    "        if not founder_info.empty:\n",
    "            founder_name = founder_info.iloc[0].get('startup_name', founder_id)\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Top {num_to_display} Investor Matches for {founder_name} ({founder_id}) (Max {top_n}) ---\")\n",
    "    if num_to_display == 0:\n",
    "        print(\"  (No matches met the criteria or processing failed)\")\n",
    "\n",
    "    for i, match in enumerate(top_matches):\n",
    "        print(f\"\\nRank {i+1}:\")\n",
    "        print(f\"  Investor: {match['investor_name']} ({match['investor_id']})\")\n",
    "        print(f\"  Match Score: {match['score']}/100\")\n",
    "        print(f\"  Reasoning: {match['reasoning']}\")\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def display_matches(founder_id: str, matches: List[Dict[str, Any]], top_n: int = 5):\n",
    "    \"\"\"\n",
    "    Displays the ranked list of top N investor matches using a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if matches is None:\n",
    "        # Use HTML for consistent rich output formatting\n",
    "        display(HTML(f\"<p style='color:red;'>Match calculation failed for founder {founder_id}.</p>\"))\n",
    "        return\n",
    "    if not matches:\n",
    "        display(HTML(f\"<p>No suitable investor matches found for founder {founder_id}.</p>\"))\n",
    "        return\n",
    "\n",
    "    # Get the top N matches\n",
    "    top_matches = matches[:top_n]\n",
    "    num_to_display = len(top_matches)\n",
    "\n",
    "    # Get founder name for display (handle potential global scope issue)\n",
    "    founder_name = founder_id # Default to ID if DataFrame not found or error occurs\n",
    "    try:\n",
    "        # Check if founders_df exists in the global scope and is a DataFrame\n",
    "        if 'founders_df' in globals() and isinstance(globals()['founders_df'], pd.DataFrame):\n",
    "            founder_info = globals()['founders_df'][globals()['founders_df']['startup_id'] == founder_id]\n",
    "            if not founder_info.empty:\n",
    "                founder_name = founder_info.iloc[0].get('startup_name', founder_id)\n",
    "        else:\n",
    "            logging.warning(\"founders_df not found or not a DataFrame in global scope. Using Founder ID for display.\")\n",
    "    except Exception as e:\n",
    "         logging.warning(f\"Error accessing founders_df for name lookup: {e}. Using Founder ID.\")\n",
    "\n",
    "\n",
    "    # --- Display Title ---\n",
    "    title_html = f\"<h3>🏆 Top {num_to_display} Investor Matches for {founder_name} ({founder_id})</h3>\"\n",
    "    display(HTML(title_html))\n",
    "\n",
    "    if num_to_display == 0:\n",
    "        display(HTML(\"<p><i>(No matches met the criteria or processing failed)</i></p>\"))\n",
    "        print(\"-------------------------------------------------------------\") # Keep separator\n",
    "        return\n",
    "\n",
    "    # --- Create DataFrame ---\n",
    "    df_data = []\n",
    "    for i, match in enumerate(top_matches):\n",
    "        df_data.append({\n",
    "            \"Rank\": i + 1,\n",
    "            \"Investor Name\": match.get('investor_name', 'N/A'),\n",
    "            \"Investor ID\": match.get('investor_id', 'N/A'),\n",
    "            \"Score\": match.get('score', 'N/A'),\n",
    "            \"Reasoning\": match.get('reasoning', 'N/A')\n",
    "        })\n",
    "\n",
    "    matches_df = pd.DataFrame(df_data)\n",
    "\n",
    "    # --- Style DataFrame (Optional but recommended) ---\n",
    "    # Center align Score and Rank, left align others\n",
    "    # Add hover effects, customize widths etc.\n",
    "    styles = [\n",
    "        {'selector': 'th', 'props': [('text-align', 'left'), ('font-weight', 'bold')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'left'), ('vertical-align', 'top')]},\n",
    "        {'selector': 'td:nth-child(1), th:nth-child(1)', 'props': [('text-align', 'center'), ('width', '5%')]}, # Rank\n",
    "        {'selector': 'td:nth-child(4), th:nth-child(4)', 'props': [('text-align', 'center'), ('width', '8%')]}, # Score\n",
    "        {'selector': 'td:nth-child(5), th:nth-child(5)', 'props': [('width', '50%')]}, # Reasoning (wider)\n",
    "        {'selector': 'tr:hover', 'props': [('background-color', '#f5f5f5')]} # Hover highlight\n",
    "    ]\n",
    "    styled_df = matches_df.style.set_table_styles(styles).hide(axis=\"index\") # Hide the default pandas index\n",
    "\n",
    "    # Display the styled DataFrame\n",
    "    display(styled_df)\n",
    "    print(\"-------------------------------------------------------------\") # Keep separator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Execution\n",
    "\n",
    "##### 5.1 Final Results\n",
    "This asynchronous function coordinates the overall process: loading data, selecting the founder, running the matching process, and displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 19:51:01,941 - INFO - --- Finding matches for Founder: FinTechFlow (STP001) ---\n",
      "2025-03-28 19:51:01,942 - INFO - Sending 8 requests to Gemini API (max concurrency: 5)...\n",
      "2025-03-28 19:51:02,493 - ERROR - Error calling Gemini API for investor INV002 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:02,494 - ERROR - Failed to get analysis for investor INV002 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,709 - ERROR - Error calling Gemini API for investor INV004 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,709 - ERROR - Failed to get analysis for investor INV004 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,713 - ERROR - Error calling Gemini API for investor INV003 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,714 - ERROR - Failed to get analysis for investor INV003 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,729 - ERROR - Error calling Gemini API for investor INV005 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,730 - ERROR - Failed to get analysis for investor INV005 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,730 - ERROR - Error calling Gemini API for investor INV006 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,731 - ERROR - Failed to get analysis for investor INV006 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,731 - ERROR - Error calling Gemini API for investor INV001 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:03,732 - ERROR - Failed to get analysis for investor INV001 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:04,046 - ERROR - Error calling Gemini API for investor INV007 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:04,047 - ERROR - Failed to get analysis for investor INV007 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:05,271 - ERROR - Error calling Gemini API for investor INV008 (Attempt 1): NotFound - 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:05,272 - ERROR - Failed to get analysis for investor INV008 after 4 attempts. Last error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "2025-03-28 19:51:05,272 - INFO - Received all responses from Gemini API.\n",
      "2025-03-28 19:51:05,273 - WARNING - No valid analysis received or processed for investor INV001\n",
      "2025-03-28 19:51:05,273 - WARNING - No valid analysis received or processed for investor INV002\n",
      "2025-03-28 19:51:05,274 - WARNING - No valid analysis received or processed for investor INV003\n",
      "2025-03-28 19:51:05,274 - WARNING - No valid analysis received or processed for investor INV004\n",
      "2025-03-28 19:51:05,274 - WARNING - No valid analysis received or processed for investor INV005\n",
      "2025-03-28 19:51:05,275 - WARNING - No valid analysis received or processed for investor INV006\n",
      "2025-03-28 19:51:05,275 - WARNING - No valid analysis received or processed for investor INV007\n",
      "2025-03-28 19:51:05,276 - WARNING - No valid analysis received or processed for investor INV008\n",
      "2025-03-28 19:51:05,276 - INFO - Analysis summary for founder STP001: 0 successful, 8 failed/skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>No suitable investor matches found for founder STP001.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if founders_df is None or investors_df is None or founders_df.empty or investors_df.empty:\n",
    "    logging.error(\"Aborting main execution: Data not loaded correctly.\")\n",
    "    \n",
    "\n",
    "# --- Select Founder to Match ---\n",
    "# Choose a founder ID from your founders.csv file\n",
    "founder_to_match_id = \"STP001\" # Example: FinTechFlow\n",
    "\n",
    "# Validate selected founder ID\n",
    "if founder_to_match_id not in founders_df['startup_id'].values:\n",
    "    logging.error(f\"Founder ID '{founder_to_match_id}' not found in the loaded founders data. Please choose a valid ID.\")\n",
    "    print(f\"\\nValid Founder IDs are: {founders_df['startup_id'].tolist()}\")\n",
    "    \n",
    "\n",
    "# --- Run Matching ---\n",
    "matches = await find_matches_for_founder(founder_to_match_id, founders_df, investors_df)\n",
    "\n",
    "# --- Display Results ---\n",
    "display_matches(founder_to_match_id, matches, top_n=5) # Display top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "This notebook demonstrated how to use the Google Gemini API to build a founder-investor matching system. It loads data, generates prompts, calls the API concurrently with rate limiting and retries, parses the results, and displays the top matches with scores and reasoning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
